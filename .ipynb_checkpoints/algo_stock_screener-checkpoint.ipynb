{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Twitter Authentication Verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/Kris/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############################################################\n",
    "\"\"\"\n",
    "    Importing initial Notebooks and Libraries\n",
    "\"\"\"\n",
    "############################################################\n",
    "\n",
    "# Jupyter notebook imports\n",
    "%run twitter_sentiment.ipynb\n",
    "\n",
    "# Library imports\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import date, timedelta\n",
    "import alpaca_trade_api as tradeapi\n",
    "from talib import RSI, OBV\n",
    "\n",
    "# Load .env enviroment variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "\"\"\"\n",
    "    API Authentications for Alpaca\n",
    "\"\"\"\n",
    "############################################################\n",
    "# Set Alpaca API key and secret\n",
    "alpaca_api_key = os.getenv(\"ALPACA_API_KEY\")\n",
    "alpaca_secret_key = os.getenv(\"ALPACA_SECRET_KEY\")\n",
    "\n",
    "api = tradeapi.REST(alpaca_api_key, alpaca_secret_key, api_version = \"v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/1D 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/15Min 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/15Min 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/1D 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/1D 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/1D 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/1D 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/1D 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/1D 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/1D 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/15Min 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/1D 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/15Min 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/1D 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/1D 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/15Min 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/1D 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/1D 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/1D 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/15Min 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/1D 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/1D 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/1D 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/1D 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/1D 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/1D 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/1D 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/1D 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/1D 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/1D 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/1D 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/1D 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/1D 3 more time(s)...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>open</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>rsi</th>\n",
       "      <th>obv</th>\n",
       "      <th>volatility</th>\n",
       "      <th>twitter_sentiment</th>\n",
       "      <th>reddit_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ATVI</th>\n",
       "      <td>2021-02-26 15:45:00-05:00</td>\n",
       "      <td>96.28</td>\n",
       "      <td>95.53</td>\n",
       "      <td>95.53</td>\n",
       "      <td>51708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMD</th>\n",
       "      <td>2021-02-26 15:45:00-05:00</td>\n",
       "      <td>84.94</td>\n",
       "      <td>84.49</td>\n",
       "      <td>84.51</td>\n",
       "      <td>258826</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AES</th>\n",
       "      <td>2021-02-26 15:45:00-05:00</td>\n",
       "      <td>26.69</td>\n",
       "      <td>26.55</td>\n",
       "      <td>26.57</td>\n",
       "      <td>57512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AFL</th>\n",
       "      <td>2021-02-26 15:45:00-05:00</td>\n",
       "      <td>48.215</td>\n",
       "      <td>47.87</td>\n",
       "      <td>47.88</td>\n",
       "      <td>82604</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AKAM</th>\n",
       "      <td>2021-02-26 15:45:00-05:00</td>\n",
       "      <td>94.69</td>\n",
       "      <td>94.42</td>\n",
       "      <td>94.43</td>\n",
       "      <td>40095</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WY</th>\n",
       "      <td>2021-02-26 15:45:00-05:00</td>\n",
       "      <td>34.03</td>\n",
       "      <td>33.88</td>\n",
       "      <td>33.88</td>\n",
       "      <td>78528</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WMB</th>\n",
       "      <td>2021-02-26 15:45:00-05:00</td>\n",
       "      <td>22.97</td>\n",
       "      <td>22.82</td>\n",
       "      <td>22.82</td>\n",
       "      <td>166772</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XEL</th>\n",
       "      <td>2021-02-26 15:45:00-05:00</td>\n",
       "      <td>58.945</td>\n",
       "      <td>58.58</td>\n",
       "      <td>58.58</td>\n",
       "      <td>66101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XRX</th>\n",
       "      <td>2021-02-26 15:45:00-05:00</td>\n",
       "      <td>25.77</td>\n",
       "      <td>25.49</td>\n",
       "      <td>25.49</td>\n",
       "      <td>62863</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZION</th>\n",
       "      <td>2021-02-26 15:45:00-05:00</td>\n",
       "      <td>53.68</td>\n",
       "      <td>53.19</td>\n",
       "      <td>53.22</td>\n",
       "      <td>13042</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>230 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           time    open    low  close  volume  rsi  obv  \\\n",
       "ATVI  2021-02-26 15:45:00-05:00   96.28  95.53  95.53   51708  NaN  NaN   \n",
       "AMD   2021-02-26 15:45:00-05:00   84.94  84.49  84.51  258826  NaN  NaN   \n",
       "AES   2021-02-26 15:45:00-05:00   26.69  26.55  26.57   57512  NaN  NaN   \n",
       "AFL   2021-02-26 15:45:00-05:00  48.215  47.87  47.88   82604  NaN  NaN   \n",
       "AKAM  2021-02-26 15:45:00-05:00   94.69  94.42  94.43   40095  NaN  NaN   \n",
       "...                         ...     ...    ...    ...     ...  ...  ...   \n",
       "WY    2021-02-26 15:45:00-05:00   34.03  33.88  33.88   78528  NaN  NaN   \n",
       "WMB   2021-02-26 15:45:00-05:00   22.97  22.82  22.82  166772  NaN  NaN   \n",
       "XEL   2021-02-26 15:45:00-05:00  58.945  58.58  58.58   66101  NaN  NaN   \n",
       "XRX   2021-02-26 15:45:00-05:00   25.77  25.49  25.49   62863  NaN  NaN   \n",
       "ZION  2021-02-26 15:45:00-05:00   53.68  53.19  53.22   13042  NaN  NaN   \n",
       "\n",
       "     volatility twitter_sentiment reddit_sentiment  \n",
       "ATVI        NaN               NaN              NaN  \n",
       "AMD         NaN               NaN              NaN  \n",
       "AES         NaN               NaN              NaN  \n",
       "AFL         NaN               NaN              NaN  \n",
       "AKAM        NaN               NaN              NaN  \n",
       "...         ...               ...              ...  \n",
       "WY          NaN               NaN              NaN  \n",
       "WMB         NaN               NaN              NaN  \n",
       "XEL         NaN               NaN              NaN  \n",
       "XRX         NaN               NaN              NaN  \n",
       "ZION        NaN               NaN              NaN  \n",
       "\n",
       "[230 rows x 10 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############################################################\n",
    "\"\"\"\n",
    "    Function scrapes Wikipedia and pulls stock data for every ticker symbol on the S&P500\n",
    "\"\"\"\n",
    "############################################################\n",
    "\n",
    "# scrapes the wikipedia page relating to the S&P 500 and returns a list of DataFrame objects\n",
    "table = pd.read_html('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies')\n",
    "\n",
    "# Since we are only interested in the current list of stocks in the S&P 500, we only need the DataFrame object at index 0\n",
    "sp500_list_df = table[0]\n",
    "sp500_tickers = sp500_list_df[[\"Symbol\", \"Security\"]]\n",
    "\n",
    "############################################################\n",
    "\"\"\"\n",
    "    Function that fetches the Twitter Sentiment score\n",
    "\"\"\"\n",
    "############################################################\n",
    "\n",
    "def fetch_twitter_sentiment(ticker, search_word):\n",
    "    score = compound_twitter_sentiment(ticker, search_word)\n",
    "    return score\n",
    "\n",
    "############################################################\n",
    "\"\"\"\n",
    "    Stock Screener for Day Trading\n",
    "    Start Main Function\n",
    "\"\"\"\n",
    "############################################################\n",
    "\n",
    "# Initialize the dataframe and set the columns\n",
    "sp500_ticker_data = []\n",
    "column_names = ['time', 'open', 'low', 'close', 'volume', 'rsi', 'obv', 'volatility', 'twitter_sentiment', 'reddit_sentiment']\n",
    "sp500_ticker_data = pd.DataFrame(columns = column_names)\n",
    "\n",
    "# for loop iterates through all tickers in S&P 500\n",
    "for tickers in range(len(sp500_tickers[\"Symbol\"])):\n",
    "    \n",
    "    # set the current ticker symbol then increases x by 1 \n",
    "    company = sp500_tickers.loc[[tickers][0]]\n",
    "    ticker = company.Symbol\n",
    "    security = company.Security\n",
    "    \n",
    "    # Set timeframe to 1 Day to capture daily Volume total\n",
    "    timeframe = \"1D\"\n",
    "    \n",
    "    # Set the limit of bars to just the previous time period\n",
    "    limit = 1\n",
    "\n",
    "    # Set end date to now for latest data (if run before market open to fetch yesterdays close)\n",
    "    end_date = pd.Timestamp.now(tz=\"America/New_York\").isoformat()\n",
    "    \n",
    "    # Initial pass of ticker symbols\n",
    "    # fetch last daily barset object for ticker and put raw data into dataframe\n",
    "    bar_set = api.get_barset(\n",
    "        ticker,\n",
    "        timeframe,\n",
    "        limit,\n",
    "        end=end_date\n",
    "        )[ticker]._raw\n",
    "    initial_check = pd.DataFrame(data=bar_set)\n",
    "    \n",
    "    ############################################################\n",
    "    \"\"\"\n",
    "    # Since Day traders generally look for stocks that have at least 1 million shares traded daily, \n",
    "    # this checks to see if the daily volume for current ticker >= 1Million.\n",
    "    # This also checks the last closing price of a ticker to see if it is above $100.\n",
    "    # If ticker volume < 1M or it's last closing price was above $100, \n",
    "    # we stop this iteration and continue to the next iteration of the loop.\n",
    "    \"\"\"\n",
    "    ############################################################\n",
    "        \n",
    "    if initial_check.loc[0, 'v'] <= 1000000 or initial_check.loc[0, 'c'] > 100:\n",
    "        continue\n",
    "    else:\n",
    "        # If the ticker passes both initial checks, it continues to calculating the additional indicators\n",
    "        # Set timeframe to 15 Minutes\n",
    "        timeframe = \"15Min\"\n",
    "    \n",
    "        #fetch ticker data \n",
    "        ticker_data = api.get_barset(\n",
    "            ticker,\n",
    "            timeframe,\n",
    "            limit,\n",
    "            end=end_date\n",
    "            )\n",
    "    \n",
    "        #ticker_data inherits dict and bars inherits list. You can iterate over them accordingly\n",
    "        for symbols in ticker_data:\n",
    "            bars = ticker_data[symbols]\n",
    "            for bar in bars:\n",
    "                sp500_ticker_data.loc[symbols, 'time'] = bar.t\n",
    "                sp500_ticker_data.loc[symbols, 'open'] = bar.o\n",
    "                sp500_ticker_data.loc[symbols, 'low'] = bar.l\n",
    "                sp500_ticker_data.loc[symbols, 'close'] = bar.c\n",
    "                sp500_ticker_data.loc[symbols, 'volume'] = bar.v\n",
    "        \n",
    "        \n",
    "        ############################################################\n",
    "        \"\"\" \n",
    "            Relative strength suggests continued outperformance while relative weakness suggests continued underperformance.\n",
    "            High RSI (usually above 70) may indicate a stock is overbought, therefore it is a sell signal. \n",
    "            Low RSI (usually below 30) indicates stock is oversold, which means a buy signal. \n",
    "        \"\"\"\n",
    "        ############################################################\n",
    "        \n",
    "        #Fetch RSI score\n",
    "        #rsi_score = RSI(sp500_ticker_data.loc[tickers, 'close'], timeperiod=1)\n",
    "        #sp500_ticker_data.loc[tickers, 'rsi'] = rsi_score\n",
    "        \n",
    "        ############################################################\n",
    "        \"\"\" \n",
    "            On-balance volume (OBV) is a technical trading momentum indicator that \n",
    "            uses volume flow to predict changes in stock price.\n",
    "            \n",
    "            When both price and OBV are making higher peaks and higher troughs, \n",
    "            the upward trend is likely to continue.\n",
    "        \"\"\"\n",
    "        ############################################################\n",
    "        \n",
    "        #Fetch On Balance Volume(OBV)\n",
    "        #obv_score = OBV(sp500_ticker_data.loc[tickers, 'close'], sp500_ticker_data.loc[tickers, 'volume'])\n",
    "        #sp500_ticker_data.loc[tickers, 'obv'] = obv_score\n",
    "        \n",
    "        ############################################################\n",
    "        \"\"\" \n",
    "            Volatility\n",
    "        \"\"\"\n",
    "        ############################################################\n",
    "        \n",
    "        # Fetch previos day data and calculate .std() ??\n",
    "        #fetch Average True Range(ATR) volatility indicator\n",
    "        #\n",
    "        #atr_score = ATR(high, low, close, timeperiod=14)\n",
    "        #sp500_ticker_data.loc[tickers, 'atr'] = atr_score\n",
    "        \n",
    "        ############################################################\n",
    "        \"\"\" \n",
    "            Twitter and Reddit Compound Sentiment\n",
    "        \"\"\"\n",
    "        ############################################################\n",
    "        \n",
    "        #fetches the Compound Sentiment score for the last 15 minutes of Tweets on Twitter\n",
    "        #twitter_comp_sentiment_score = fetch_twitter_sentiment(ticker, security)\n",
    "        #sp500_ticker_data.loc[tickers, 'twitter_sentiment'] = twitter_comp_sentiment_score\n",
    "        \n",
    "        #fetch reddit sentiment\n",
    "        #reddit_sentiment = fetch_reddit_sentiment(ticker)\n",
    "        #sp500_ticker_data.loc[x, 'reddit_sentiment'] = reddit_sentiment\n",
    "    \n",
    "sp500_ticker_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "(0, 'rsi')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m           Traceback (most recent call last)",
      "\u001b[0;32m/opt/anaconda3/envs/nlpenv/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2894\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2895\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: (0, 'rsi')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-ff7fb35309df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# adds up all indicator column scores and calculates the total_indi_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrows\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindicators_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mindicators_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'total_trading_score'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindicators_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rsi'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mindicators_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'obv'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mindicators_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'volatility'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mindicators_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'twitter_sentiment'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mindicators_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'reddit_sentiment'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# sorts indidcator_df by total_indie_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/nlpenv/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2900\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2901\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2902\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2903\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2904\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/nlpenv/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2895\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: (0, 'rsi')"
     ]
    }
   ],
   "source": [
    "############################################################\n",
    "\"\"\" \n",
    "\n",
    "    Adds up scores of each indicator and returns a sorted list with Top 5 stock tickers\n",
    "    \n",
    "\"\"\"\n",
    "############################################################\n",
    "\n",
    "indicators_df = pd.DataFrame(sp500_ticker_data)\n",
    "\n",
    "# adds up all indicator column scores and calculates the total_indi_score\n",
    "for rows in range(len(indicators_df)):\n",
    "    indicators_df[rows, 'total_trading_score'] = float(indicators_df[rows, 'rsi'] + indicators_df[rows, 'obv'] + indicators_df[rows, 'volatility'] + indicators_df[rows, 'twitter_sentiment'] + indicators_df[rows, 'reddit_sentiment'])\n",
    "    \n",
    "# sorts indidcator_df by total_indie_score\n",
    "indicators_df.sort_by(by='total_trading_score', ascending=True)\n",
    "\n",
    "# saves top 5 tickers into top5_stocks_df[\"tickers\"]\n",
    "top5_stocks_df = indicators_df[:4]\n",
    "\n",
    "# return top 5 stock recommendations\n",
    "top5_stocks_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
